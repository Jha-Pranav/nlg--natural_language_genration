{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "# Load an spacy model (supported models are \"es\", \"en\" and \"pt\") \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(WordnetAnnotator(nlp.lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = nlp('backup')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('backup.n.01.backup'),\n",
       " Lemma('stand-in.n.01.stand-in'),\n",
       " Lemma('stand-in.n.01.substitute'),\n",
       " Lemma('stand-in.n.01.relief'),\n",
       " Lemma('stand-in.n.01.reliever'),\n",
       " Lemma('stand-in.n.01.backup'),\n",
       " Lemma('stand-in.n.01.backup_man'),\n",
       " Lemma('stand-in.n.01.fill-in'),\n",
       " Lemma('accompaniment.n.02.accompaniment'),\n",
       " Lemma('accompaniment.n.02.musical_accompaniment'),\n",
       " Lemma('accompaniment.n.02.backup'),\n",
       " Lemma('accompaniment.n.02.support'),\n",
       " Lemma('backup.n.04.backup'),\n",
       " Lemma('backup.n.04.computer_backup'),\n",
       " Lemma('backing.n.01.backing'),\n",
       " Lemma('backing.n.01.backup'),\n",
       " Lemma('backing.n.01.championship'),\n",
       " Lemma('backing.n.01.patronage')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token._.wordnet.synsets()\n",
    "token._.wordnet.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'cinema',\n",
       " 'aviation',\n",
       " 'free_time',\n",
       " 'music',\n",
       " 'dance',\n",
       " 'acoustics',\n",
       " 'theatre',\n",
       " 'computer_science',\n",
       " 'finance',\n",
       " 'politics']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token._.wordnet.wordnet_domains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can (catch|take_in|see|watch|view) summary (info|data|information) about policy (condition|status) per (server|host) . The summary (info|data|information) (provide|render|furnish|supply) the (server|host) (name) , (country|res_publica|body_politic|commonwealth|state|land|nation) and the total count for each (server|host) . The (server|host) RLTIA00007 (exist|comprise|represent|constitute|be|make_up) most complaint among all other (server|host) .\n"
     ]
    }
   ],
   "source": [
    "economy_domains = [ \"statistics\",\"computer_science\"]\n",
    "enriched_sentence = []\n",
    "sentence = nlp(\"You can view summary information about policy status per host.The summary information provides the Host Name, STATE and the total count for each server. The Host RLTIA00007 is most complaint among all other servers.\")\n",
    "\n",
    "# For each token in the sentence\n",
    "for token in sentence:\n",
    "    # We get those synsets within the desired domains\n",
    "    synsets = token._.wordnet.wordnet_synsets_for_domain(economy_domains)\n",
    "    if not synsets:\n",
    "        enriched_sentence.append(token.text)\n",
    "    else:\n",
    "        lemmas_for_synset = [lemma for s in synsets for lemma in s.lemma_names()]\n",
    "        # If we found a synset in the economy domains\n",
    "        # we get the variants and add them to the enriched sentence\n",
    "#         print(lemmas_for_synset)\n",
    "        enriched_sentence.append('({})'.format('|'.join(set(lemmas_for_synset))))\n",
    "\n",
    "# Let's see our enriched sentence\n",
    "print(' '.join(enriched_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class set_nlg_gramopt(object):  # noqa: class to be used as a decorator\n",
    "    \"\"\"Decorator for adding callables to grammar options.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, func):\n",
    "        \n",
    "        func.gramopt = True\n",
    "        for k, v in self.kwargs.items():\n",
    "            if not getattr(func, k, False):\n",
    "                setattr(func, k, v)\n",
    "        return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@set_nlg_gramopt(source='G', fe_name='Singularize')\n",
    "def singular(word):\n",
    "    \"\"\"\n",
    "    Singularize a word.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        Word to singularize.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Singular of `word`.\n",
    "    \"\"\"\n",
    "    return word\n",
    "singular('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Singularize': {'fe_name': 'Singularize', 'source': 'G', 'func_name': '_61'}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs = {}\n",
    "module = globals().copy()\n",
    "for attrname in module:\n",
    "    obj = module[attrname]\n",
    "    if obj and getattr(obj, 'gramopt', False):\n",
    "        funcs[obj.fe_name] = {\n",
    "            'fe_name': obj.fe_name, 'source': obj.source, 'func_name': attrname\n",
    "        }\n",
    "funcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
